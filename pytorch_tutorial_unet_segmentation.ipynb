{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Netを用いたセグメンテーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ読み込みの準備\n",
    "正解ラベル画像がない学習画像が存在するため、正解のある画像のみのリストを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pathlist(dir_image, dir_label):\n",
    "    paths_image = glob.glob(dir_image + \"/*\")\n",
    "    paths_label = glob.glob(dir_label + \"/*\")\n",
    "\n",
    "    if len(paths_image) == 0 or len(paths_label) == 0:\n",
    "        raise FileNotFoundError(\"Could not load images.\")\n",
    "    # 正解ラベルの拡張子を.pngに書き換えたものがセグメンテーションに使える画像ファイル名\n",
    "    filenames = list(map(lambda path: path.split(os.sep)[-1].split(\".\")[0], paths_label))\n",
    "    paths_image = list(map(lambda filename: dir_image + \"/\" + filename + \".jpg\", filenames))\n",
    "    return paths_image, paths_label\n",
    "\n",
    "dir_image = \"./VOCtrainval_11-May-2012/VOCdevkit/VOC2012/JPEGImages\"\n",
    "dir_label = \"./VOCtrainval_11-May-2012/VOCdevkit/VOC2012/SegmentationClass\"\n",
    "\n",
    "image_paths, label_paths = generate_pathlist(dir_image, dir_label)\n",
    "\n",
    "# 分割してtrain val testのパスのリストを用意する\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットクラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SegmentDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.cls_idx = [i for i in range(22)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        image = image.resize((256,256))\n",
    "        image = np.asarray(image)\n",
    "        image = torch.from_numpy(image.astype(np.float32)).clone()\n",
    "        image = image.permute(2,0,1) #次元の並び替え\n",
    "\n",
    "        label = Image.open(self.label_paths[idx])\n",
    "        label = label.resize((256,256))\n",
    "        label = np.asarray(label)\n",
    "        label = np.where(label == 255, 21, label) # 境界線マスクを255から21に変更\n",
    "\n",
    "        #onehotベクトル化        \n",
    "        label = torch.from_numpy(label.astype(np.float32)).clone()\n",
    "        label = torch.nn.functional.one_hot(label.long()).to(torch.float32)\n",
    "        label = label.permute(2,0,1)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = SegmentDataset(image_paths, label_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[131., 132., 133.,  ..., 182., 182., 182.],\n",
      "          [132., 133., 134.,  ..., 184., 183., 183.],\n",
      "          [133., 134., 134.,  ..., 184., 183., 183.],\n",
      "          ...,\n",
      "          [  6.,   8.,  12.,  ...,  11.,  13.,  14.],\n",
      "          [  7.,  11.,  11.,  ...,  17.,  16.,  17.],\n",
      "          [  6.,   7.,  11.,  ...,  15.,  15.,  15.]],\n",
      "\n",
      "         [[193., 194., 196.,  ..., 232., 232., 232.],\n",
      "          [194., 195., 197.,  ..., 234., 233., 233.],\n",
      "          [195., 196., 197.,  ..., 234., 233., 233.],\n",
      "          ...,\n",
      "          [ 14.,  14.,  16.,  ...,  30.,  31.,  32.],\n",
      "          [ 16.,  17.,  15.,  ...,  36.,  34.,  35.],\n",
      "          [ 16.,  15.,  16.,  ...,  35.,  32.,  32.]],\n",
      "\n",
      "         [[208., 209., 211.,  ..., 240., 241., 241.],\n",
      "          [209., 210., 212.,  ..., 241., 242., 242.],\n",
      "          [210., 211., 212.,  ..., 242., 242., 242.],\n",
      "          ...,\n",
      "          [ 13.,  15.,  20.,  ...,  34.,  35.,  36.],\n",
      "          [ 15.,  18.,  19.,  ...,  40.,  38.,  39.],\n",
      "          [ 15.,  18.,  22.,  ...,  39.,  39.,  39.]]],\n",
      "\n",
      "\n",
      "        [[[214., 212., 212.,  ..., 225., 224., 221.],\n",
      "          [211., 209., 211.,  ..., 223., 221., 218.],\n",
      "          [212., 210., 211.,  ..., 222., 222., 220.],\n",
      "          ...,\n",
      "          [ 95., 100., 102.,  ..., 198., 198., 195.],\n",
      "          [ 96.,  95.,  96.,  ..., 197., 196., 195.],\n",
      "          [ 93., 100., 101.,  ..., 194., 195., 195.]],\n",
      "\n",
      "         [[214., 212., 212.,  ..., 225., 224., 221.],\n",
      "          [211., 209., 211.,  ..., 223., 221., 218.],\n",
      "          [212., 210., 211.,  ..., 222., 222., 220.],\n",
      "          ...,\n",
      "          [ 81.,  87.,  88.,  ..., 198., 198., 193.],\n",
      "          [ 83.,  82.,  83.,  ..., 197., 196., 193.],\n",
      "          [ 80.,  87.,  87.,  ..., 194., 195., 193.]],\n",
      "\n",
      "         [[214., 212., 212.,  ..., 225., 224., 221.],\n",
      "          [211., 209., 211.,  ..., 223., 221., 218.],\n",
      "          [212., 210., 211.,  ..., 222., 222., 220.],\n",
      "          ...,\n",
      "          [ 66.,  71.,  73.,  ..., 198., 198., 194.],\n",
      "          [ 67.,  66.,  67.,  ..., 197., 196., 194.],\n",
      "          [ 64.,  71.,  72.,  ..., 194., 195., 194.]]],\n",
      "\n",
      "\n",
      "        [[[165., 169., 164.,  ...,  60.,  57.,  59.],\n",
      "          [166., 173., 171.,  ...,  62.,  60.,  60.],\n",
      "          [169., 173., 172.,  ...,  60.,  62.,  61.],\n",
      "          ...,\n",
      "          [ 96.,  98.,  96.,  ...,  59.,  61.,  66.],\n",
      "          [ 95.,  97.,  95.,  ...,  66.,  66.,  67.],\n",
      "          [ 92.,  94.,  94.,  ...,  66.,  71.,  69.]],\n",
      "\n",
      "         [[167., 172., 167.,  ...,  57.,  54.,  56.],\n",
      "          [166., 174., 174.,  ...,  59.,  57.,  57.],\n",
      "          [170., 174., 175.,  ...,  57.,  59.,  58.],\n",
      "          ...,\n",
      "          [ 97., 100., 100.,  ...,  67.,  68.,  73.],\n",
      "          [ 96.,  99.,  99.,  ...,  74.,  71.,  72.],\n",
      "          [ 93.,  97.,  98.,  ...,  72.,  76.,  74.]],\n",
      "\n",
      "         [[148., 151., 145.,  ...,  41.,  36.,  37.],\n",
      "          [150., 155., 153.,  ...,  43.,  40.,  40.],\n",
      "          [154., 157., 156.,  ...,  42.,  43.,  42.],\n",
      "          ...,\n",
      "          [ 80.,  80.,  82.,  ...,  73.,  72.,  78.],\n",
      "          [ 79.,  79.,  81.,  ...,  77.,  76.,  79.],\n",
      "          [ 76.,  77.,  80.,  ...,  72.,  80.,  80.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[190., 189., 189.,  ..., 158., 158., 157.],\n",
      "          [190., 188., 188.,  ..., 159., 160., 160.],\n",
      "          [188., 188., 188.,  ..., 160., 161., 159.],\n",
      "          ...,\n",
      "          [ 83.,  74.,  78.,  ...,  70.,  79.,  91.],\n",
      "          [ 79.,  77.,  82.,  ...,  87.,  81.,  85.],\n",
      "          [ 68.,  72.,  67.,  ...,  97.,  96.,  91.]],\n",
      "\n",
      "         [[200., 199., 201.,  ..., 178., 179., 178.],\n",
      "          [200., 199., 200.,  ..., 179., 180., 180.],\n",
      "          [199., 200., 201.,  ..., 180., 181., 179.],\n",
      "          ...,\n",
      "          [110., 101., 105.,  ...,  80.,  89., 102.],\n",
      "          [106., 104., 109.,  ..., 100.,  94.,  97.],\n",
      "          [ 95.,  98.,  95.,  ..., 110., 108., 102.]],\n",
      "\n",
      "         [[199., 198., 199.,  ..., 185., 184., 183.],\n",
      "          [199., 198., 198.,  ..., 186., 186., 187.],\n",
      "          [198., 198., 199.,  ..., 187., 188., 186.],\n",
      "          ...,\n",
      "          [131., 121., 123.,  ...,  96.,  99., 108.],\n",
      "          [126., 126., 130.,  ..., 112., 109., 111.],\n",
      "          [115., 121., 118.,  ..., 119., 123., 118.]]],\n",
      "\n",
      "\n",
      "        [[[ 72.,  72.,  71.,  ...,  69.,  71.,  70.],\n",
      "          [ 72.,  72.,  73.,  ...,  69.,  71.,  71.],\n",
      "          [ 73.,  73.,  72.,  ...,  71.,  72.,  71.],\n",
      "          ...,\n",
      "          [ 81.,  81.,  81.,  ...,  76.,  76.,  76.],\n",
      "          [ 80.,  82.,  83.,  ...,  77.,  76.,  77.],\n",
      "          [ 81.,  81.,  82.,  ...,  76.,  76.,  77.]],\n",
      "\n",
      "         [[105., 105., 105.,  ..., 105., 105., 104.],\n",
      "          [105., 105., 107.,  ..., 105., 105., 105.],\n",
      "          [106., 106., 106.,  ..., 107., 106., 105.],\n",
      "          ...,\n",
      "          [116., 116., 116.,  ..., 113., 113., 113.],\n",
      "          [115., 117., 118.,  ..., 112., 113., 114.],\n",
      "          [116., 116., 117.,  ..., 112., 113., 114.]],\n",
      "\n",
      "         [[140., 140., 140.,  ..., 141., 142., 141.],\n",
      "          [140., 140., 142.,  ..., 141., 142., 142.],\n",
      "          [141., 141., 141.,  ..., 143., 143., 142.],\n",
      "          ...,\n",
      "          [146., 146., 146.,  ..., 139., 140., 140.],\n",
      "          [147., 147., 146.,  ..., 140., 140., 141.],\n",
      "          [146., 146., 145.,  ..., 139., 139., 140.]]],\n",
      "\n",
      "\n",
      "        [[[ 87.,  88.,  89.,  ...,  95.,  94.,  92.],\n",
      "          [ 89.,  90.,  89.,  ...,  97.,  96.,  93.],\n",
      "          [ 89.,  92.,  90.,  ...,  98.,  98.,  96.],\n",
      "          ...,\n",
      "          [  2.,   1.,   0.,  ...,  65.,  64.,  62.],\n",
      "          [  2.,   1.,   1.,  ...,  66.,  61.,  61.],\n",
      "          [  2.,   2.,   1.,  ...,  64.,  59.,  59.]],\n",
      "\n",
      "         [[ 80.,  81.,  84.,  ...,  93.,  91.,  89.],\n",
      "          [ 82.,  83.,  84.,  ...,  96.,  93.,  90.],\n",
      "          [ 82.,  85.,  85.,  ...,  97.,  96.,  93.],\n",
      "          ...,\n",
      "          [  1.,   1.,   2.,  ...,  67.,  67.,  64.],\n",
      "          [  1.,   1.,   1.,  ...,  68.,  65.,  65.],\n",
      "          [  2.,   2.,   2.,  ...,  66.,  63.,  63.]],\n",
      "\n",
      "         [[ 62.,  63.,  65.,  ...,  72.,  74.,  72.],\n",
      "          [ 64.,  65.,  65.,  ...,  75.,  75.,  72.],\n",
      "          [ 64.,  67.,  66.,  ...,  76.,  76.,  73.],\n",
      "          ...,\n",
      "          [  0.,   0.,   0.,  ...,  54.,  55.,  53.],\n",
      "          [  0.,   0.,   0.,  ...,  55.,  51.,  51.],\n",
      "          [  0.,   0.,   0.,  ...,  52.,  49.,  49.]]]])\n",
      "Shape of X [N, C, H, W]:  torch.Size([16, 3, 256, 256])\n",
      "Shape of y:  torch.Size([16, 22, 256, 256]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# データローダーの作成\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "#validation_dataloader = DataLoader(validation_data, batch_size=batch_size)\n",
    "#test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U-Netの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "class TwoConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, middle_channels, kernel_size = 3, padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm2d(middle_channels)\n",
    "        self.rl = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(middle_channels, out_channels, kernel_size = 3, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.rl(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.rl(x)\n",
    "        return x\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = 2, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn2(x)\n",
    "        return x\n",
    "\n",
    "class UNet_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.TCB1 = TwoConvBlock(3, 64, 64)\n",
    "        self.TCB2 = TwoConvBlock(64, 128, 128)\n",
    "        self.TCB3 = TwoConvBlock(128, 256, 256)\n",
    "        self.TCB4 = TwoConvBlock(256, 512, 512)\n",
    "        self.TCB5 = TwoConvBlock(512, 1024, 1024)\n",
    "        self.TCB6 = TwoConvBlock(1024, 512, 512)\n",
    "        self.TCB7 = TwoConvBlock(512, 256, 256)\n",
    "        self.TCB8 = TwoConvBlock(256, 128, 128)\n",
    "        self.TCB9 = TwoConvBlock(128, 64, 64)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride = 2)\n",
    "        \n",
    "        self.UC1 = UpConv(1024, 512) \n",
    "        self.UC2 = UpConv(512, 256) \n",
    "        self.UC3 = UpConv(256, 128) \n",
    "        self.UC4= UpConv(128, 64)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(64, 22, kernel_size = 1)\n",
    "        self.soft = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.TCB1(x)\n",
    "        x1 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB2(x)\n",
    "        x2 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB3(x)\n",
    "        x3 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB4(x)\n",
    "        x4 = x\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.TCB5(x)\n",
    "\n",
    "        x = self.UC1(x)\n",
    "        x = torch.cat([x4, x], dim = 1)\n",
    "        x = self.TCB6(x)\n",
    "\n",
    "        x = self.UC2(x)\n",
    "        x = torch.cat([x3, x], dim = 1)\n",
    "        x = self.TCB7(x)\n",
    "\n",
    "        x = self.UC3(x)\n",
    "        x = torch.cat([x2, x], dim = 1)\n",
    "        x = self.TCB8(x)\n",
    "\n",
    "        x = self.UC4(x)\n",
    "        x = torch.cat([x1, x], dim = 1)\n",
    "        x = self.TCB9(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        #x = self.soft(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "model = UNet_2D().to(device)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 損失誤差を計算\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        epoch_loss += loss.item()\n",
    "        # バックプロパゲーション\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    epoch_loss /= size\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    validation_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            validation_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    validation_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {validation_loss:>8f} \\n\")\n",
    "    return validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation損失をもとに最適epochを決定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "best_epoch = 0\n",
    "min_loss = 1000\n",
    "os.makedirs(\"./model/\", exist_ok=True)\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "    train_losses.append(train_loss)\n",
    "#    validation_loss = validation(validation_dataloader, model)\n",
    "#    validation_losses.append(validation_loss)\n",
    "#    if validation_loss < min_loss:\n",
    "#        best_epoch = t+1\n",
    "#        min_loss = validation_loss\n",
    "#    torch.save(model.state_dict(), \"./model/model_\"+str(t+1)+\".pth\")\n",
    "#print(best_epoch)\n",
    "\n",
    "#model = UNet_2D()\n",
    "#model.load_state_dict(torch.load(\"model/model_\"+str(best_epoch)+\".pth\"))\n",
    "#test(test_dataloader, model)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失グラフ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(validation_losses)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
